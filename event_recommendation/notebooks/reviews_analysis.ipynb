{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reviews Data Analysis\n",
        "\n",
        "This notebook analyzes the reviews data from `reviews_rag_2000.csv` to gain insights into:\n",
        "- Rating distribution\n",
        "- Event type popularity\n",
        "- Location-based patterns\n",
        "- Sentiment analysis\n",
        "- Common themes and keywords\n",
        "- Temporal trends\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âŒ ERROR: Missing required packages!\n",
            "   Missing: seaborn\n",
            "\n",
            "ðŸ“¦ To install, run in terminal:\n",
            "   source ../activate/bin/activate\n",
            "   pip install seaborn\n",
            "\n",
            "   Or install all at once:\n",
            "   pip install pandas numpy matplotlib seaborn\n",
            "\n",
            "   Then restart this kernel (Kernel â†’ Restart)\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "Please install: seaborn",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   pip install pandas numpy matplotlib seaborn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m   Then restart this kernel (Kernel â†’ Restart)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(missing_packages)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# All imports successful\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n",
            "\u001b[0;31mImportError\u001b[0m: Please install: seaborn"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "# Check if packages are installed first\n",
        "missing_packages = []\n",
        "try:\n",
        "    import pandas as pd\n",
        "except ImportError:\n",
        "    missing_packages.append(\"pandas\")\n",
        "try:\n",
        "    import numpy as np\n",
        "except ImportError:\n",
        "    missing_packages.append(\"numpy\")\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "except ImportError:\n",
        "    missing_packages.append(\"matplotlib\")\n",
        "try:\n",
        "    import seaborn as sns\n",
        "except ImportError:\n",
        "    missing_packages.append(\"seaborn\")\n",
        "\n",
        "if missing_packages:\n",
        "    print(f\"Missing packages: {', '.join(missing_packages)}\")\n",
        "    print(f\"Install with: pip install {' '.join(missing_packages)}\")\n",
        "    raise ImportError(f\"Please install: {', '.join(missing_packages)}\")\n",
        "\n",
        "# All imports successful\n",
        "import re\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Set style for better visualizations\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# Get project root directory\n",
        "current_dir = os.getcwd()\n",
        "if os.path.basename(current_dir) == \"notebooks\":\n",
        "    project_root = os.path.dirname(current_dir)\n",
        "else:\n",
        "    project_root = current_dir\n",
        "\n",
        "csv_path = os.path.join(project_root, \"documents\", \"Reviews\", \"reviews_rag_2000.csv\")\n",
        "print(f\"âœ“ All packages loaded successfully\")\n",
        "print(f\"Loading reviews from: {csv_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Display basic info\n",
        "print(f\"Total reviews: {len(df)}\")\n",
        "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data cleaning and preprocessing\n",
        "# Remove empty column if exists\n",
        "df = df.dropna(axis=1, how='all')\n",
        "\n",
        "# Convert rating to numeric\n",
        "df['rating'] = pd.to_numeric(df['rating'], errors='coerce')\n",
        "\n",
        "# Parse dates\n",
        "df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')\n",
        "\n",
        "# Extract event type and location from review text\n",
        "def extract_event_type(text):\n",
        "    if pd.isna(text):\n",
        "        return None\n",
        "    # Pattern: UPPERCASE WORDS before \"at\"\n",
        "    match = re.search(r'([A-Z][A-Z\\s/]+?)\\s+at\\s+', str(text))\n",
        "    return match.group(1).strip() if match else None\n",
        "\n",
        "def extract_location(text):\n",
        "    if pd.isna(text):\n",
        "        return None\n",
        "    # Pattern: \"at CITY YMCA\" or \"in CITY\"\n",
        "    match = re.search(r'(?:at|in)\\s+([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)?)\\s+YMCA', str(text))\n",
        "    if match:\n",
        "        return match.group(1).strip()\n",
        "    # Try alternative pattern\n",
        "    match = re.search(r'in\\s+([A-Z][a-z]+)', str(text))\n",
        "    return match.group(1).strip() if match else None\n",
        "\n",
        "df['event_type'] = df['review_text'].apply(extract_event_type)\n",
        "df['location'] = df['review_text'].apply(extract_location)\n",
        "\n",
        "print(f\"\\nData shape: {df.shape}\")\n",
        "print(f\"\\nMissing values:\")\n",
        "print(df.isnull().sum())\n",
        "print(f\"\\nSample with extracted fields:\")\n",
        "df[['rating', 'event_type', 'location', 'review_text']].head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Rating Distribution Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rating distribution\n",
        "rating_counts = df['rating'].value_counts().sort_index()\n",
        "rating_pct = df['rating'].value_counts(normalize=True).sort_index() * 100\n",
        "\n",
        "print(\"Rating Distribution:\")\n",
        "for rating in sorted(rating_counts.index):\n",
        "    print(f\"{rating} stars: {rating_counts[rating]} reviews ({rating_pct[rating]:.1f}%)\")\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Bar chart\n",
        "axes[0].bar(rating_counts.index, rating_counts.values, color='steelblue', alpha=0.7)\n",
        "axes[0].set_xlabel('Rating')\n",
        "axes[0].set_ylabel('Number of Reviews')\n",
        "axes[0].set_title('Rating Distribution (Count)')\n",
        "axes[0].set_xticks(sorted(rating_counts.index))\n",
        "for i, v in enumerate(rating_counts.values):\n",
        "    axes[0].text(rating_counts.index[i], v, str(v), ha='center', va='bottom')\n",
        "\n",
        "# Pie chart\n",
        "axes[1].pie(rating_counts.values, labels=[f\"{r} stars\" for r in rating_counts.index], \n",
        "            autopct='%1.1f%%', startangle=90)\n",
        "axes[1].set_title('Rating Distribution (Percentage)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nAverage Rating: {df['rating'].mean():.2f}\")\n",
        "print(f\"Median Rating: {df['rating'].median():.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Event Type Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Event type analysis\n",
        "event_type_counts = df['event_type'].value_counts().head(20)\n",
        "\n",
        "print(f\"Total unique event types: {df['event_type'].nunique()}\")\n",
        "print(f\"\\nTop 20 Event Types by Review Count:\")\n",
        "print(event_type_counts)\n",
        "\n",
        "# Average rating by event type\n",
        "event_ratings = df.groupby('event_type')['rating'].agg(['mean', 'count']).sort_values('count', ascending=False).head(20)\n",
        "event_ratings.columns = ['avg_rating', 'review_count']\n",
        "\n",
        "print(f\"\\nTop 20 Event Types by Review Count with Average Ratings:\")\n",
        "print(event_ratings)\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
        "\n",
        "# Review count by event type\n",
        "axes[0].barh(range(len(event_type_counts)), event_type_counts.values, color='steelblue', alpha=0.7)\n",
        "axes[0].set_yticks(range(len(event_type_counts)))\n",
        "axes[0].set_yticklabels(event_type_counts.index)\n",
        "axes[0].set_xlabel('Number of Reviews')\n",
        "axes[0].set_title('Top 20 Event Types by Review Count')\n",
        "axes[0].invert_yaxis()\n",
        "\n",
        "# Average rating by event type (for events with at least 5 reviews)\n",
        "event_ratings_filtered = event_ratings[event_ratings['review_count'] >= 5].head(20)\n",
        "axes[1].barh(range(len(event_ratings_filtered)), event_ratings_filtered['avg_rating'].values, \n",
        "             color='green', alpha=0.7)\n",
        "axes[1].set_yticks(range(len(event_ratings_filtered)))\n",
        "axes[1].set_yticklabels(event_ratings_filtered.index)\n",
        "axes[1].set_xlabel('Average Rating')\n",
        "axes[1].set_title('Top 20 Event Types by Average Rating (min 5 reviews)')\n",
        "axes[1].axvline(x=df['rating'].mean(), color='red', linestyle='--', label='Overall Average')\n",
        "axes[1].legend()\n",
        "axes[1].invert_yaxis()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Location Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Location analysis\n",
        "location_counts = df['location'].value_counts().head(15)\n",
        "\n",
        "print(f\"Total unique locations: {df['location'].nunique()}\")\n",
        "print(f\"\\nTop 15 Locations by Review Count:\")\n",
        "print(location_counts)\n",
        "\n",
        "# Average rating by location\n",
        "location_ratings = df.groupby('location')['rating'].agg(['mean', 'count']).sort_values('count', ascending=False).head(15)\n",
        "location_ratings.columns = ['avg_rating', 'review_count']\n",
        "\n",
        "print(f\"\\nTop 15 Locations by Review Count with Average Ratings:\")\n",
        "print(location_ratings)\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
        "\n",
        "# Review count by location\n",
        "axes[0].barh(range(len(location_counts)), location_counts.values, color='coral', alpha=0.7)\n",
        "axes[0].set_yticks(range(len(location_counts)))\n",
        "axes[0].set_yticklabels(location_counts.index)\n",
        "axes[0].set_xlabel('Number of Reviews')\n",
        "axes[0].set_title('Top 15 Locations by Review Count')\n",
        "axes[0].invert_yaxis()\n",
        "\n",
        "# Average rating by location (for locations with at least 5 reviews)\n",
        "location_ratings_filtered = location_ratings[location_ratings['review_count'] >= 5].head(15)\n",
        "axes[1].barh(range(len(location_ratings_filtered)), location_ratings_filtered['avg_rating'].values, \n",
        "             color='purple', alpha=0.7)\n",
        "axes[1].set_yticks(range(len(location_ratings_filtered)))\n",
        "axes[1].set_yticklabels(location_ratings_filtered.index)\n",
        "axes[1].set_xlabel('Average Rating')\n",
        "axes[1].set_title('Top 15 Locations by Average Rating (min 5 reviews)')\n",
        "axes[1].axvline(x=df['rating'].mean(), color='red', linestyle='--', label='Overall Average')\n",
        "axes[1].legend()\n",
        "axes[1].invert_yaxis()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Text Analysis - Keywords and Themes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Text analysis\n",
        "import string\n",
        "from collections import Counter\n",
        "\n",
        "# Combine all review texts\n",
        "all_text = ' '.join(df['review_text'].dropna().astype(str))\n",
        "\n",
        "# Common words (excluding stop words and common terms)\n",
        "stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'was', 'were', 'is', 'are', 'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'must', 'can', 'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they', 'my', 'your', 'his', 'her', 'its', 'our', 'their'}\n",
        "\n",
        "# Extract words\n",
        "words = re.findall(r'\\b[a-z]+\\b', all_text.lower())\n",
        "words = [w for w in words if w not in stop_words and len(w) > 3]\n",
        "word_counts = Counter(words)\n",
        "\n",
        "print(f\"Total words analyzed: {len(words)}\")\n",
        "print(f\"\\nTop 30 Most Common Words:\")\n",
        "for word, count in word_counts.most_common(30):\n",
        "    print(f\"{word}: {count}\")\n",
        "\n",
        "# Visualization\n",
        "top_words = dict(word_counts.most_common(20))\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.barh(range(len(top_words)), list(top_words.values()), color='teal', alpha=0.7)\n",
        "plt.yticks(range(len(top_words)), list(top_words.keys()))\n",
        "plt.xlabel('Frequency')\n",
        "plt.title('Top 20 Most Common Words in Reviews')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Review Length Analysis by Rating\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze review length and content by rating\n",
        "df['review_length'] = df['review_text'].str.len()\n",
        "df['word_count'] = df['review_text'].str.split().str.len()\n",
        "\n",
        "# Review length by rating\n",
        "length_by_rating = df.groupby('rating')[['review_length', 'word_count']].mean()\n",
        "\n",
        "print(\"Average Review Length by Rating:\")\n",
        "print(length_by_rating)\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Character length by rating\n",
        "axes[0].bar(length_by_rating.index, length_by_rating['review_length'], color='steelblue', alpha=0.7)\n",
        "axes[0].set_xlabel('Rating')\n",
        "axes[0].set_ylabel('Average Character Count')\n",
        "axes[0].set_title('Average Review Length (Characters) by Rating')\n",
        "axes[0].set_xticks(length_by_rating.index)\n",
        "\n",
        "# Word count by rating\n",
        "axes[1].bar(length_by_rating.index, length_by_rating['word_count'], color='coral', alpha=0.7)\n",
        "axes[1].set_xlabel('Rating')\n",
        "axes[1].set_ylabel('Average Word Count')\n",
        "axes[1].set_title('Average Review Length (Words) by Rating')\n",
        "axes[1].set_xticks(length_by_rating.index)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Sample reviews by rating\n",
        "print(\"\\nSample Reviews by Rating:\")\n",
        "for rating in sorted(df['rating'].dropna().unique()):\n",
        "    sample = df[df['rating'] == rating]['review_text'].iloc[0] if len(df[df['rating'] == rating]) > 0 else None\n",
        "    if sample:\n",
        "        print(f\"\\n{rating} stars: {sample[:150]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Event Type and Location Cross-Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cross-analysis: Event type vs Location\n",
        "# Get top event types and locations\n",
        "top_events = df['event_type'].value_counts().head(10).index\n",
        "top_locations = df['location'].value_counts().head(10).index\n",
        "\n",
        "cross_tab = pd.crosstab(df['event_type'], df['location'], margins=True)\n",
        "cross_tab_filtered = cross_tab.loc[list(top_events) + ['All'], list(top_locations) + ['All']]\n",
        "\n",
        "print(\"Event Type vs Location Cross-Tabulation (Top 10x10):\")\n",
        "print(cross_tab_filtered)\n",
        "\n",
        "# Heatmap\n",
        "plt.figure(figsize=(14, 8))\n",
        "cross_tab_heatmap = pd.crosstab(df['event_type'], df['location'])\n",
        "cross_tab_heatmap_filtered = cross_tab_heatmap.loc[list(top_events), list(top_locations)]\n",
        "sns.heatmap(cross_tab_heatmap_filtered, annot=True, fmt='d', cmap='YlOrRd', cbar_kws={'label': 'Review Count'})\n",
        "plt.title('Event Type vs Location Heatmap (Top 10x10)')\n",
        "plt.xlabel('Location')\n",
        "plt.ylabel('Event Type')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Key Insights Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate summary insights\n",
        "print(\"=\" * 60)\n",
        "print(\"KEY INSIGHTS SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\n1. Overall Statistics:\")\n",
        "print(f\"   - Total Reviews: {len(df)}\")\n",
        "print(f\"   - Average Rating: {df['rating'].mean():.2f}\")\n",
        "print(f\"   - Unique Event Types: {df['event_type'].nunique()}\")\n",
        "print(f\"   - Unique Locations: {df['location'].nunique()}\")\n",
        "\n",
        "print(f\"\\n2. Top Performing Event Types (by average rating, min 10 reviews):\")\n",
        "top_rated_events = df.groupby('event_type')['rating'].agg(['mean', 'count'])\n",
        "top_rated_events = top_rated_events[top_rated_events['count'] >= 10].sort_values('mean', ascending=False).head(5)\n",
        "for event, row in top_rated_events.iterrows():\n",
        "    print(f\"   - {event}: {row['mean']:.2f} stars ({int(row['count'])} reviews)\")\n",
        "\n",
        "print(f\"\\n3. Most Reviewed Event Types:\")\n",
        "most_reviewed = df['event_type'].value_counts().head(5)\n",
        "for event, count in most_reviewed.items():\n",
        "    avg_rating = df[df['event_type'] == event]['rating'].mean()\n",
        "    print(f\"   - {event}: {count} reviews (avg: {avg_rating:.2f} stars)\")\n",
        "\n",
        "print(f\"\\n4. Top Locations (by review count):\")\n",
        "top_locations = df['location'].value_counts().head(5)\n",
        "for location, count in top_locations.items():\n",
        "    avg_rating = df[df['location'] == location]['rating'].mean()\n",
        "    print(f\"   - {location}: {count} reviews (avg: {avg_rating:.2f} stars)\")\n",
        "\n",
        "print(f\"\\n5. Rating Distribution:\")\n",
        "for rating in sorted(df['rating'].dropna().unique()):\n",
        "    count = len(df[df['rating'] == rating])\n",
        "    pct = (count / len(df)) * 100\n",
        "    print(f\"   - {rating} stars: {count} reviews ({pct:.1f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Export Analysis Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export processed data and summaries\n",
        "output_dir = os.path.join(project_root, \"notebooks\", \"analysis_output\")\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Export processed dataframe\n",
        "df.to_csv(os.path.join(output_dir, \"reviews_processed.csv\"), index=False)\n",
        "print(f\"Exported processed data to: {os.path.join(output_dir, 'reviews_processed.csv')}\")\n",
        "\n",
        "# Export event type summary\n",
        "event_summary = df.groupby('event_type')['rating'].agg(['mean', 'count', 'std']).sort_values('count', ascending=False)\n",
        "event_summary.columns = ['avg_rating', 'review_count', 'rating_std']\n",
        "event_summary.to_csv(os.path.join(output_dir, \"event_type_summary.csv\"))\n",
        "print(f\"Exported event type summary to: {os.path.join(output_dir, 'event_type_summary.csv')}\")\n",
        "\n",
        "# Export location summary\n",
        "location_summary = df.groupby('location')['rating'].agg(['mean', 'count', 'std']).sort_values('count', ascending=False)\n",
        "location_summary.columns = ['avg_rating', 'review_count', 'rating_std']\n",
        "location_summary.to_csv(os.path.join(output_dir, \"location_summary.csv\"))\n",
        "print(f\"Exported location summary to: {os.path.join(output_dir, 'location_summary.csv')}\")\n",
        "\n",
        "print(f\"\\nAll analysis results exported to: {output_dir}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
