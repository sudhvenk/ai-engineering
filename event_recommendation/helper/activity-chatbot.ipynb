{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dbd450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use groq client and connect to openai opensource model    \n",
    "\n",
    "import os\n",
    "import groq\n",
    "\n",
    "groq_client = groq.Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "OPENSOURCE_OSS_MODEL = \"openai/gpt-oss-120b\"\n",
    "\n",
    "# create system prompt\n",
    "SYSTEM_PROMPT = \"You are an Activity Recommendation Assistant. \\\n",
    "\\\n",
    "Your job is to help users discover suitable activities, classes, or event types \\\n",
    "based on their age, interests, physical comfort level, time availability, and goals. \\\n",
    "You must follow these rules: \\\n",
    "1. Use ONLY the information provided in the context and user messages. \\\n",
    "2. Do NOT invent activities, classes, or benefits that are not explicitly stated. \\\n",
    "3. If information is missing, ask a clarifying question instead of guessing. \\\n",
    "4. Be respectful of physical limitations and accessibility needs. \\\n",
    "5. Do NOT provide medical advice. Phrase benefits in general wellness terms. \\\n",
    "6. When recommending activities, include: \\\n",
    "   - Activity name \\\n",
    "   - Typical intensity level \\\n",
    "   - Typical session length \\\n",
    "   - Recommended weekly frequency \\\n",
    "   - Why it fits the user’s preferences \\\n",
    "7. If multiple activities fit, rank them from best to least suitable. \\\n",
    "8. If nothing fits well, explain why and suggest alternatives. \\\n",
    "\\\n",
    "Your tone should be friendly, practical, and encouraging. \\\n",
    "\"\n",
    "\n",
    "# create user prompt for the system prompt above\n",
    "USER_PROMPT = \"You are continuing a conversation with a user about activities and events. \\\n",
    "\\\n",
    "Conversation history (user inputs only): \\\n",
    "{USER_HISTORY} \\\n",
    "\\\n",
    "Current user request: \\\n",
    "{CURRENT_MESSAGE} \\\n",
    "\\\n",
    "Relevant activity knowledge: \\\n",
    "{RAG_CONTEXT} \\\n",
    "\\\n",
    "Instructions: \\\n",
    "- Recommend the top 2 suitable activity types from the knowledge provided. \\\n",
    "- Explain clearly why each recommendation fits the user. \\\n",
    "- Get the exact event name from the context provided and which location the event is located at. \\\n",
    "- Include intensity, session length, and typical weekly frequency. \\\n",
    "- Cite the activity source using [filename | activity name]. \\\n",
    "- If the knowledge is insufficient, say what is missing. \\\n",
    "\"\n",
    "\n",
    "# create user prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a320a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "843c7105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from sklearn.manifold import TSNE\n",
    "from chromadb import PersistentClient\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060fcc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional, Tuple, Iterable\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "# -----------------------------\n",
    "# 1) Parsing & chunking\n",
    "# -----------------------------\n",
    "\n",
    "EVENT_HEADING_RE = re.compile(r\"^###\\s+(.*)\\s*$\", re.MULTILINE)\n",
    "FIELD_RE = {\n",
    "    \"event_type\": re.compile(r\"^\\s*-\\s*Event Type:\\s*(.+?)\\s*$\", re.MULTILINE | re.IGNORECASE),\n",
    "    \"category\": re.compile(r\"^\\s*-\\s*Category:\\s*(.+?)\\s*$\", re.MULTILINE | re.IGNORECASE),\n",
    "    \"age_tags\": re.compile(r\"^\\s*-\\s*Age Tags:\\s*(.+?)\\s*$\", re.MULTILINE | re.IGNORECASE),\n",
    "    \"instructor\": re.compile(r\"^\\s*-\\s*(Instructor|Facilitator):\\s*(.+?)\\s*$\", re.MULTILINE | re.IGNORECASE),\n",
    "    \"date_range\": re.compile(r\"^\\s*-\\s*Date Range:\\s*(.+?)\\s*$\", re.MULTILINE | re.IGNORECASE),\n",
    "    \"time_slots\": re.compile(r\"^\\s*-\\s*Time Slots:\\s*(.+?)\\s*$\", re.MULTILINE | re.IGNORECASE),\n",
    "    \"duration\": re.compile(r\"^\\s*-\\s*Duration:\\s*(.+?)\\s*$\", re.MULTILINE | re.IGNORECASE),\n",
    "    \"spots\": re.compile(r\"^\\s*-\\s*Spots:\\s*(.+?)\\s*$\", re.MULTILINE | re.IGNORECASE),\n",
    "}\n",
    "\n",
    "CENTER_RE = re.compile(r\"^##\\s+(.+?)\\s*$\", re.MULTILINE)\n",
    "LOCATION_RE = re.compile(r\"^\\*\\*Location:\\*\\*\\s*(.+?)\\s*$\", re.MULTILINE)\n",
    "TYPE_RE = re.compile(r\"^\\*\\*Type:\\*\\*\\s*(.+?)\\s*$\", re.MULTILINE)\n",
    "\n",
    "PAGE_RE = re.compile(r\"^#\\s+PAGE\\s+\\d+\\s+—\\s+(.+?)\\s*$\", re.MULTILINE)\n",
    "\n",
    "\n",
    "def _safe_find(regex: re.Pattern, text: str) -> Optional[str]:\n",
    "    m = regex.search(text)\n",
    "    return m.group(1).strip() if m else None\n",
    "\n",
    "\n",
    "def _safe_find2(regex: re.Pattern, text: str) -> Optional[str]:\n",
    "    m = regex.search(text)\n",
    "    return m.group(2).strip() if m else None\n",
    "\n",
    "\n",
    "def parse_center_metadata(md_text: str, source: str) -> Dict[str, Optional[str]]:\n",
    "    center_name = _safe_find(CENTER_RE, md_text)\n",
    "    location = _safe_find(LOCATION_RE, md_text)\n",
    "    center_type = _safe_find(TYPE_RE, md_text)\n",
    "\n",
    "    city, state = None, None\n",
    "    if location:\n",
    "        # \"Salem, Massachusetts\" or \"Plymouth, Massachusetts\"\n",
    "        parts = [p.strip() for p in location.split(\",\")]\n",
    "        if len(parts) >= 2:\n",
    "            city, state = parts[0], parts[1]\n",
    "\n",
    "    return {\n",
    "        \"source\": source,\n",
    "        \"center_name\": center_name,\n",
    "        \"center_type\": center_type,\n",
    "        \"city\": city,\n",
    "        \"state\": state,\n",
    "    }\n",
    "\n",
    "\n",
    "def split_event_blocks(md_text: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Returns list of (event_title, event_block_text).\n",
    "    Event blocks start with '### ' and continue until next '### ' or end.\n",
    "    \"\"\"\n",
    "    matches = list(EVENT_HEADING_RE.finditer(md_text))\n",
    "    blocks: List[Tuple[str, str]] = []\n",
    "    for i, m in enumerate(matches):\n",
    "        title = m.group(1).strip()\n",
    "        start = m.start()\n",
    "        end = matches[i + 1].start() if i + 1 < len(matches) else len(md_text)\n",
    "        block = md_text[start:end].strip()\n",
    "        blocks.append((title, block))\n",
    "    return blocks\n",
    "\n",
    "\n",
    "def parse_event_metadata(event_title: str, block: str) -> Dict[str, Optional[str]]:\n",
    "    # Event Type may appear as \"Event Type:\" or \"Category:\" depending on file style\n",
    "    event_type = _safe_find(FIELD_RE[\"event_type\"], block) or _safe_find(FIELD_RE[\"category\"], block)\n",
    "\n",
    "    age_tags = _safe_find(FIELD_RE[\"age_tags\"], block)\n",
    "    instructor = _safe_find2(FIELD_RE[\"instructor\"], block)\n",
    "    date_range = _safe_find(FIELD_RE[\"date_range\"], block)\n",
    "    time_slots = _safe_find(FIELD_RE[\"time_slots\"], block)\n",
    "    duration = _safe_find(FIELD_RE[\"duration\"], block)\n",
    "    spots = _safe_find(FIELD_RE[\"spots\"], block)\n",
    "\n",
    "    return {\n",
    "        \"event_title\": event_title,\n",
    "        \"event_type\": event_type,\n",
    "        \"age_tags\": age_tags,\n",
    "        \"instructor\": instructor,\n",
    "        \"date_range\": date_range,\n",
    "        \"time_slots\": time_slots,\n",
    "        \"duration\": duration,\n",
    "        \"spots\": spots,\n",
    "    }\n",
    "\n",
    "\n",
    "def build_event_documents(md_text: str, source: str) -> List[Document]:\n",
    "    center_md = parse_center_metadata(md_text, source)\n",
    "    docs: List[Document] = []\n",
    "\n",
    "    for title, block in split_event_blocks(md_text):\n",
    "        meta = parse_event_metadata(title, block)\n",
    "        combined_meta = {**center_md, **meta, \"doc_type\": \"event\"}\n",
    "\n",
    "        # Use compact but rich page_content for embeddings\n",
    "        content = (\n",
    "            f\"Center: {center_md.get('center_name')} ({center_md.get('center_type')})\\n\"\n",
    "            f\"Location: {center_md.get('city')}, {center_md.get('state')}\\n\"\n",
    "            f\"Event: {title}\\n\"\n",
    "            f\"Event Type: {meta.get('event_type')}\\n\"\n",
    "            f\"Age Tags: {meta.get('age_tags')}\\n\"\n",
    "            f\"Instructor: {meta.get('instructor')}\\n\"\n",
    "            f\"Date Range: {meta.get('date_range')}\\n\"\n",
    "            f\"Time Slots: {meta.get('time_slots')}\\n\"\n",
    "            f\"Duration: {meta.get('duration')}\\n\"\n",
    "            f\"Spots: {meta.get('spots')}\\n\\n\"\n",
    "            f\"Raw Block:\\n{block}\\n\"\n",
    "        ).strip()\n",
    "\n",
    "        docs.append(Document(page_content=content, metadata=combined_meta))\n",
    "\n",
    "    return docs\n",
    "\n",
    "\n",
    "def build_activitytype_documents(md_text: str, source: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Simple section chunking:\n",
    "    - Split by '## ' headings (category sections) if present\n",
    "    - Else split by '### ' headings\n",
    "    Keeps chunks reasonably sized; you can add recursive splitting if needed.\n",
    "    \"\"\"\n",
    "    # Prefer ## sections\n",
    "    if \"## \" in md_text:\n",
    "        splitter = re.compile(r\"(?m)^##\\s+\")\n",
    "        parts = splitter.split(md_text)\n",
    "        # parts[0] is preamble; subsequent parts start after heading marker\n",
    "        docs: List[Document] = []\n",
    "        preamble = parts[0].strip()\n",
    "        if preamble:\n",
    "            docs.append(Document(page_content=preamble, metadata={\"source\": source, \"doc_type\": \"activity_type\"}))\n",
    "\n",
    "        # Re-add the heading marker for clarity in content\n",
    "        for sec in parts[1:]:\n",
    "            sec = sec.strip()\n",
    "            if not sec:\n",
    "                continue\n",
    "            # Extract heading line\n",
    "            lines = sec.splitlines()\n",
    "            heading = lines[0].strip()\n",
    "            body = \"\\n\".join(lines[1:]).strip()\n",
    "            chunk = f\"## {heading}\\n{body}\".strip()\n",
    "            docs.append(\n",
    "                Document(\n",
    "                    page_content=chunk,\n",
    "                    metadata={\"source\": source, \"doc_type\": \"activity_type\", \"activity_heading\": heading},\n",
    "                )\n",
    "            )\n",
    "        return docs\n",
    "\n",
    "    # Fallback: split by ### blocks\n",
    "    docs = []\n",
    "    for title, block in split_event_blocks(md_text):  # reuse ### splitter\n",
    "        docs.append(\n",
    "            Document(\n",
    "                page_content=f\"### {title}\\n{block}\",\n",
    "                metadata={\"source\": source, \"doc_type\": \"activity_type\", \"activity_heading\": title},\n",
    "            )\n",
    "        )\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f2d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5363c9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in: /Users/adipole/github/ai_portfolio/event_recommendation/documents\n",
      "Found folders: ['/Users/adipole/github/ai_portfolio/event_recommendation/documents/activityType', '/Users/adipole/github/ai_portfolio/event_recommendation/documents/Events', '/Users/adipole/github/ai_portfolio/event_recommendation/documents/Reviews']\n",
      "Loaded 6 documents from activityType\n",
      "Loaded 0 documents from Events\n",
      "Loaded 0 documents from Reviews\n",
      "Loaded 6 documents total\n"
     ]
    }
   ],
   "source": [
    "# Load in everything in the knowledgebase using LangChain's loaders\n",
    "\n",
    "# Get the project root directory\n",
    "# In notebooks, we need to find the project root relative to current working directory\n",
    "current_dir = os.getcwd()\n",
    "# If we're in helper/, go up one level; otherwise assume we're at project root\n",
    "if os.path.basename(current_dir) == \"helper\":\n",
    "    project_root = os.path.dirname(current_dir)\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "documents_path = os.path.join(project_root, \"documents\")\n",
    "\n",
    "# point this to the documents folder\n",
    "folders = glob.glob(os.path.join(documents_path, \"*\"))\n",
    "\n",
    "documents = []\n",
    "print(f\"Looking in: {documents_path}\")\n",
    "print(f\"Found folders: {folders}\")\n",
    "for folder in folders:\n",
    "    if os.path.isdir(folder):\n",
    "        doc_type = os.path.basename(folder)\n",
    "        loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs={'encoding': 'utf-8'})\n",
    "        folder_docs = loader.load()\n",
    "        print(f\"Loaded {len(folder_docs)} documents from {doc_type}\")\n",
    "        for doc in folder_docs:\n",
    "            doc.metadata[\"doc_type\"] = doc_type\n",
    "            documents.append(doc)\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "719fe3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pydantic model class for the response from the model with the format:\n",
    "# activty_category: string\n",
    "# activity_name: string\n",
    "# activity_description: string\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Activity(BaseModel):\n",
    "    activity_category: str\n",
    "    activity_name: str\n",
    "    activity_description: str   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44492de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 12 chunks\n",
      "page_content='# Dancing Activities\n",
      "\n",
      "Dance activities combine rhythmic movement, coordination, balance, and cardiovascular exercise. They also offer strong cognitive and social benefits through pattern learning, memory, and group interaction.' metadata={'source': '/Users/adipole/github/ai_portfolio/event_recommendation/documents/activityType/dancing.md', 'doc_type': 'activityType'}\n",
      "Vectorstore created with 12 documents\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1efcec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "import re\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Chunk:\n",
    "    text: str\n",
    "    start_idx: int\n",
    "    end_idx: int\n",
    "    avg_similarity: Optional[float] = None\n",
    "\n",
    "\n",
    "class SemanticChunker:\n",
    "    \"\"\"\n",
    "    Semantic chunking using sentence-transformers cosine similarity between consecutive sentences.\n",
    "\n",
    "    Heuristics:\n",
    "      - Start a new chunk when similarity < threshold\n",
    "      - Enforce min/max chunk sizes\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        similarity_threshold: float = 0.72,\n",
    "        min_sentences: int = 3,\n",
    "        max_sentences: int = 10,\n",
    "    ):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        self.min_sentences = min_sentences\n",
    "        self.max_sentences = max_sentences\n",
    "\n",
    "    @staticmethod\n",
    "    def _split_sentences(text: str) -> List[str]:\n",
    "        # Simple sentence splitter; good enough for markdown prose.\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "        if not text:\n",
    "            return []\n",
    "        # split on sentence end punctuation + space\n",
    "        sents = re.split(r\"(?<=[.!?])\\s+\", text)\n",
    "        return [s.strip() for s in sents if s.strip()]\n",
    "\n",
    "    @staticmethod\n",
    "    def _cos_sim(a: np.ndarray, b: np.ndarray) -> float:\n",
    "        # a,b assumed normalized\n",
    "        return float(np.dot(a, b))\n",
    "\n",
    "    def chunk(self, text: str) -> List[Chunk]:\n",
    "        sentences = self._split_sentences(text)\n",
    "        if not sentences:\n",
    "            return []\n",
    "\n",
    "        # Embed all sentences, normalize for cosine similarity via dot product\n",
    "        emb = self.model.encode(sentences, normalize_embeddings=True)\n",
    "        emb = np.asarray(emb, dtype=np.float32)\n",
    "\n",
    "        chunks: List[Chunk] = []\n",
    "        cur_start = 0\n",
    "        cur_end = 0\n",
    "        sims: List[float] = []\n",
    "\n",
    "        def flush(end_idx: int):\n",
    "            nonlocal cur_start, cur_end, sims\n",
    "            chunk_text = \" \".join(sentences[cur_start:end_idx])\n",
    "            avg = float(np.mean(sims)) if sims else None\n",
    "            chunks.append(Chunk(text=chunk_text, start_idx=cur_start, end_idx=end_idx, avg_similarity=avg))\n",
    "            cur_start = end_idx\n",
    "            cur_end = end_idx\n",
    "            sims = []\n",
    "\n",
    "        cur_end = 1\n",
    "        for i in range(1, len(sentences)):\n",
    "            # similarity between consecutive sentences\n",
    "            sim = self._cos_sim(emb[i - 1], emb[i])\n",
    "            sims.append(sim)\n",
    "\n",
    "            cur_len = (cur_end - cur_start)\n",
    "\n",
    "            should_split = (\n",
    "                (sim < self.similarity_threshold and cur_len >= self.min_sentences)\n",
    "                or (cur_len >= self.max_sentences)\n",
    "            )\n",
    "\n",
    "            if should_split:\n",
    "                flush(cur_end)\n",
    "            cur_end += 1\n",
    "\n",
    "        # flush last chunk\n",
    "        if cur_start < len(sentences):\n",
    "            flush(len(sentences))\n",
    "\n",
    "        return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86c9d1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 24 chunks\n",
      "Vectorstore created with 24 documents\n"
     ]
    }
   ],
   "source": [
    "# Divide into chunks using SemanticChunker\n",
    "# Note: SemanticChunker requires embeddings - using HuggingFace embeddings\n",
    "# load HG_KEY from .env\n",
    "load_dotenv()\n",
    "HG_KEY = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "db_name = \"vector_db\"\n",
    "collection_name = \"docs\"\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "chunker = SemanticChunker(similarity_threshold=0.70, min_sentences=2, max_sentences=4)\n",
    "\n",
    "# Chunk each document and convert to Document objects\n",
    "chunked_documents = []\n",
    "for doc in documents:\n",
    "    # Chunk the document's text content\n",
    "    chunks = chunker.chunk(doc.page_content)\n",
    "    # Convert each chunk to a Document object with original metadata\n",
    "    for chunk in chunks:\n",
    "        chunked_documents.append(\n",
    "            Document(\n",
    "                page_content=chunk.text,\n",
    "                metadata=doc.metadata.copy()\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(f\"Split into {len(chunked_documents)} chunks\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunked_documents,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=db_name\n",
    ")\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "print(\"Vectorstore created with\", len(chunked_documents), \"documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d802bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(query_string): \n",
    "    from langchain_core.documents import Document\n",
    "    \n",
    "    RETRIEVAL_K = 2\n",
    "    query_vec = OpenAIEmbeddings(model=\"text-embedding-3-small\").embed_query(query_string)\n",
    "    results = retriever.query(query_embeddings=[query_vec], n_results=RETRIEVAL_K)\n",
    "    print(\"Length of results: \", len(results['documents']))\n",
    "    # Convert ChromaDB results to Document objects\n",
    "    retrieved_docs = []\n",
    "    if results['documents'] and len(results['documents']) > 0:\n",
    "        for i, doc_text in enumerate(results['documents'][0]):\n",
    "            metadata = results['metadatas'][0][i] if results['metadatas'] and len(results['metadatas']) > 0 else {}\n",
    "            retrieved_docs.append(Document(page_content=doc_text, metadata=metadata))\n",
    "    \n",
    "    print(\"Retrieved documents:\")\n",
    "    print(retrieved_docs)\n",
    "    return retrieved_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48f1d2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of results:  1\n",
      "Retrieved documents:\n",
      "[Document(metadata={'source': '/Users/adipole/github/ai_portfolio/event_recommendation/documents/activityType/aquatics.md', 'doc_type': 'activityType'}, page_content='## AQUA CARDIO\\nA water-based cardiovascular workout using continuous movement to elevate heart rate with minimal joint impact. **Intensity:** Moderate | **Session:** 45–60 min | **Frequency:** 2–4/week  \\n**Benefits:** Cardio endurance, circulation, calorie burn  \\n**Ailments:** Joint pain, low stamina, back discomfort  \\n\\n## AQUA CARDIO DANCE\\nDance-style choreography combined with water resistance for rhythm-driven cardio. **Intensity:** Low–Moderate | **Session:** 45–60 min | **Frequency:** 1–3/week  \\n**Benefits:** Coordination, balance, enjoyment  \\n**Ailments:** Balance issues, mood decline  \\n\\n## AQUA FIT\\nFull-body aquatic workout combining aerobics, toning, and resistance. **Intensity:** Moderate | **Session:** 45–60 min | **Frequency:** 2–4/week  \\n**Benefits:** Muscle tone, endurance, joint mobility  \\n**Ailments:** Arthritis, osteoporosis risk  \\n\\n## AQUA INTERVALS\\nAlternating high-effort bursts with recovery phases in water. **Intensity:** Moderate–High | **Session:** 30–60 min | **Frequency:** 1–3/week  \\n**Benefits:** Metabolism, fat burn, cardio capacity  \\n**Ailments:** Poor cardio fitness, insulin resistance  \\n\\n## AQUA RUMBA\\nLatin-inspired water dance focused on fun and light cardio. **Intensity:** Low–Moderate | **Session:** 30–45 min | **Frequency:** 1–3/week  \\n**Benefits:** Mood, coordination, social engagement  \\n**Ailments:** Low motivation, joint stiffness  \\n\\n## AQUA ZUMBA®\\nHigh-energy Zumba choreography adapted for water resistance. **Intensity:** Moderate | **Session:** 45–60 min | **Frequency:** 1–3/week  \\n**Benefits:** Cardio fitness, calorie burn  \\n**Ailments:** Joint sensitivity, stress  \\n\\n## ARTHRITIS AQUA FITNESS\\nGentle aquatic exercise designed for arthritis and rheumatic conditions. **Intensity:** Low | **Session:** 30–45 min | **Frequency:** 2–5/week  \\n**Benefits:** Pain reduction, mobility, confidence  \\n**Ailments:** Arthritis, fibromyalgia  \\n\\n## WATER BARRE\\nBallet-inspired movements adapted for aquatic resistance. **Intensity:** Low–Moderate | **Session:** 45–60 min | **Frequency:** 2–3/week  \\n**Benefits:** Balance, posture, core stability  \\n**Ailments:** Balance instability, weak core  \\n\\n## AQUA YOGA\\nTraditional yoga postures adapted to water for support and relaxation. **Intensity:** Low–Moderate | **Session:** 45–60 min | **Frequency:** 2–4/week  \\n**Benefits:** Flexibility, relaxation, balance  \\n**Ailments:** Stress, chronic pain  \\n\\n## AQUA YIN YOGA\\nLong-held passive stretches performed in water for deep release. **Intensity:** Low | **Session:** 45–60 min | **Frequency:** 1–3/week  \\n**Benefits:** Recovery, joint health, sleep quality  \\n**Ailments:** Chronic stiffness, anxiety  \\n\\n## AQUA PILATES\\nPilates-based core strengthening using water resistance. **Intensity:** Low–Moderate | **Session:** 45–60 min | **Frequency:** 2–3/week  \\n**Benefits:** Core strength, posture  \\n**Ailments:** Lower back pain, balance issues\\n'), Document(metadata={'doc_type': 'activityType', 'source': '/Users/adipole/github/ai_portfolio/event_recommendation/documents/activityType/aquatics.md'}, page_content='# Aquatics Activities\\n\\nAquatics activities are water-based exercise programs that use buoyancy and water resistance to reduce joint stress while improving cardiovascular health, strength, flexibility, and balance. These programs are widely used for rehabilitation, senior fitness, and low-impact conditioning.')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/Users/adipole/github/ai_portfolio/event_recommendation/documents/activityType/aquatics.md', 'doc_type': 'activityType'}, page_content='## AQUA CARDIO\\nA water-based cardiovascular workout using continuous movement to elevate heart rate with minimal joint impact. **Intensity:** Moderate | **Session:** 45–60 min | **Frequency:** 2–4/week  \\n**Benefits:** Cardio endurance, circulation, calorie burn  \\n**Ailments:** Joint pain, low stamina, back discomfort  \\n\\n## AQUA CARDIO DANCE\\nDance-style choreography combined with water resistance for rhythm-driven cardio. **Intensity:** Low–Moderate | **Session:** 45–60 min | **Frequency:** 1–3/week  \\n**Benefits:** Coordination, balance, enjoyment  \\n**Ailments:** Balance issues, mood decline  \\n\\n## AQUA FIT\\nFull-body aquatic workout combining aerobics, toning, and resistance. **Intensity:** Moderate | **Session:** 45–60 min | **Frequency:** 2–4/week  \\n**Benefits:** Muscle tone, endurance, joint mobility  \\n**Ailments:** Arthritis, osteoporosis risk  \\n\\n## AQUA INTERVALS\\nAlternating high-effort bursts with recovery phases in water. **Intensity:** Moderate–High | **Session:** 30–60 min | **Frequency:** 1–3/week  \\n**Benefits:** Metabolism, fat burn, cardio capacity  \\n**Ailments:** Poor cardio fitness, insulin resistance  \\n\\n## AQUA RUMBA\\nLatin-inspired water dance focused on fun and light cardio. **Intensity:** Low–Moderate | **Session:** 30–45 min | **Frequency:** 1–3/week  \\n**Benefits:** Mood, coordination, social engagement  \\n**Ailments:** Low motivation, joint stiffness  \\n\\n## AQUA ZUMBA®\\nHigh-energy Zumba choreography adapted for water resistance. **Intensity:** Moderate | **Session:** 45–60 min | **Frequency:** 1–3/week  \\n**Benefits:** Cardio fitness, calorie burn  \\n**Ailments:** Joint sensitivity, stress  \\n\\n## ARTHRITIS AQUA FITNESS\\nGentle aquatic exercise designed for arthritis and rheumatic conditions. **Intensity:** Low | **Session:** 30–45 min | **Frequency:** 2–5/week  \\n**Benefits:** Pain reduction, mobility, confidence  \\n**Ailments:** Arthritis, fibromyalgia  \\n\\n## WATER BARRE\\nBallet-inspired movements adapted for aquatic resistance. **Intensity:** Low–Moderate | **Session:** 45–60 min | **Frequency:** 2–3/week  \\n**Benefits:** Balance, posture, core stability  \\n**Ailments:** Balance instability, weak core  \\n\\n## AQUA YOGA\\nTraditional yoga postures adapted to water for support and relaxation. **Intensity:** Low–Moderate | **Session:** 45–60 min | **Frequency:** 2–4/week  \\n**Benefits:** Flexibility, relaxation, balance  \\n**Ailments:** Stress, chronic pain  \\n\\n## AQUA YIN YOGA\\nLong-held passive stretches performed in water for deep release. **Intensity:** Low | **Session:** 45–60 min | **Frequency:** 1–3/week  \\n**Benefits:** Recovery, joint health, sleep quality  \\n**Ailments:** Chronic stiffness, anxiety  \\n\\n## AQUA PILATES\\nPilates-based core strengthening using water resistance. **Intensity:** Low–Moderate | **Session:** 45–60 min | **Frequency:** 2–3/week  \\n**Benefits:** Core strength, posture  \\n**Ailments:** Lower back pain, balance issues\\n'),\n",
       " Document(metadata={'doc_type': 'activityType', 'source': '/Users/adipole/github/ai_portfolio/event_recommendation/documents/activityType/aquatics.md'}, page_content='# Aquatics Activities\\n\\nAquatics activities are water-based exercise programs that use buoyancy and water resistance to reduce joint stress while improving cardiovascular health, strength, flexibility, and balance. These programs are widely used for rehabilitation, senior fitness, and low-impact conditioning.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_context(\"I am a 34 year old woman who loves a water activity for knee pain, low cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04f19c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import gradio chat interface\n",
    "import gradio as gr\n",
    "\n",
    "# groq client to openai opensource openai oss model\n",
    "# use the system prompt and user prompt to generate the response\n",
    "def chat(message, history):\n",
    "\n",
    "    user_prompt = USER_PROMPT\n",
    "\n",
    "\n",
    "    \n",
    "    # add previous user messages only\n",
    "    # Handle Gradio 6.x history format - each item is a tuple (user_msg, assistant_msg)\n",
    "       # add previous user messages only\n",
    "    for h in history:\n",
    "        if h.get(\"role\") == \"user\":\n",
    "            user_prompt += f\"\\n\\nUser: {h['content']}\"\n",
    "\n",
    "    user_prompt += f\"\\n\\nUser: {message}\"\n",
    "\n",
    "    # RAG retrieval uses the current message as query (not the full prompt)\n",
    "    retrieved_docs = retriever.invoke(message)\n",
    "\n",
    "    rag_context = \"\\n\\n---\\n\\n\".join(\n",
    "        [f\"[{d.metadata.get('source','')}] {d.page_content}\" for d in retrieved_docs]\n",
    "    )\n",
    "\n",
    "    final_user_prompt = f\"\"\"\n",
    "{user_prompt}\n",
    "\n",
    "Relevant knowledge base context:\n",
    "{rag_context}\n",
    "\n",
    "Answer using ONLY the context above when answering factual questions about activities.\n",
    "If the context is insufficient, say what is missing.\n",
    "\"\"\"\n",
    "    \n",
    "\n",
    "    response = groq_client.chat.completions.create(\n",
    "        model=OPENSOURCE_OSS_MODEL,\n",
    "        messages=[{\"role\": \"system\", \"content\": SYSTEM_PROMPT}, {\"role\": \"user\", \"content\": final_user_prompt}],\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# gradio chat interface\n",
    "demo = gr.ChatInterface(chat)\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "activate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
